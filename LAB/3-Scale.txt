
#########################################
# Scaling up and down in Kubernetes cluster

$ kubectl run my-nginx --image=nginx --replicas=3 --port=80

$ kubectl get pods

$ kubectl get rs

$ kubectl scale --replicas=1 deployment/my-nginx

$ kubectl get rs

$ kubectl get pods

$ kubectl get services
#####################################################




#####################################
Create an Nginx deployment 
#####################################
Deploy image

[root@master~]# kubectl run nginx --image=nginx
deployment.apps "nginx" created

[root@master~]# kubectl get deployment
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     1         1         1            1           10s
Go through the worker nodes and I found 1 instance of nginx running on master2.

Then create a service and expose port 80 on the master node's public ip

[root@master~]#  kubectl expose deployment nginx --name=nginx-lb --external-ip=192.168.1.70 --port=80 --target-port=80 --type=LoadBalancer
service "nginx-lb" exposed
[root@master~]# kubectl get service
NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP      10.96.0.1       <none>        443/TCP        25m
nginx-lb     LoadBalancer   10.103.218.95   192.168.1.70    80:32450/TCP   7s

Scale out the deployment

[root@master~]# kubectl scale deployment nginx --replicas=4
deployment.extensions "nginx" scaled
[root@master~]# kubectl get deployment
NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     4         4         4            4           2m

[root@master~]# kubectl get pods -o wide
NAME                                READY     STATUS    RESTARTS   AGE       IP          NODE
nginx-deployment-57664d6d66-9vs2h   1/1       Running   1          22m       10.44.0.3   master1
nginx-deployment-57664d6d66-bznch   1/1       Running   1          22m       10.44.0.4   master1
nginx-deployment-57664d6d66-m6b2h   1/1       Running   0          22m       10.36.0.1   master2
nginx-deployment-57664d6d66-xxs56   1/1       Running   0          22m       10.36.0.2   master2




Make nginx serve a docroot from the local fs

Here the previous deployment and service will be removed. New ones will be deployed with a spec file. The nginx will also be configured to serve a local directory as docroot instead of the default /usr/share/nginx/html.

On each worker machine, create a ```/tmp/var/sites/default```. On the master node, create a deployment spec called nginx-deployment.yml

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      run: web
  replicas: 2
  template:
    metadata:
      labels:
        run: web
    spec:
      containers:
        - image: nginx
          name: nginx-localroot
          ports:
            - containerPort: 80
          volumeMounts:
            - mountPath: /usr/share/nginx/html
              name: nginx-root
      volumes:
        - name: nginx-root
          hostPath:
            # directory location on host
            path: /tmp/var/sites/default
            type: Directory
---
apiVersion: v1
kind: Service
metadata:
  labels:
    run: web
  name: nginx-lb
spec:
  ports:
  - port: 80
    protocol: TCP
  externalIPs:
  - 192.168.1.70
  selector:
    run: web
  type: LoadBalancer
Delete the previous deployment and then deploy a new one with the yml file.

[root@master~]# kubectl  delete deployment nginx
[root@master~]# kubectl  delete service nginx-lb
[root@master~]# kubectl  create -f nginx-deployment.yml
On each worker mode, create an index.html under /var/sites/default and test it from the master node

[root@master~]# curl http://192.168.1.70
Hello this is node2

[root@master~]# curl http://192.168.1.70
Hello this is node1
Dump service in yaml

This is one way to see how to write an yaml based on existing service.

kubectl get svc nginx-lb -o yaml

